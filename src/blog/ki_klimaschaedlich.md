---
#icon: "" # Icon auf der Kachel ausschalten durch löschen des #
type: "Beitrag" # Typ ist in diesem Ordner automatsch Meldung kann aber hier überschrieben werden z.B. mit "Veröffentlichung" - der Typ erscheint in der Kachel

#permalink: 
aktuell: ja # Wenn dieser Post nicht mehr aktuell ist einfach diese Zeile mit # auskommentieren
datum: "2025-02-10"
autorin: Friederike Hildebrandt, Constanze Kurz


bild: "/assets/images/ki_image.jpg"
#bildunterschrift: "Das Podium mit Francesca Bria, Johanna Graf und Friederike Hildebrandt"

title: "Generative KI - Klimaschädlich by Design"
description: Ein Blogbeitrag über die ökologischen Kosten des KI-Investment-Booms

# Zwischen Überschrift und Text
einleitung: Dass die generative KI wegen ihrer exorbitant hohen Rechenleistungen sehr viel Energie verbraucht, weiß jeder, der es wissen möchte. Aber wie hoch die ökologischen Kosten des KI-Investment-Booms tatsächlich sind und wie stark sie künftig wachsen werden, darüber reden noch zu wenige.

# Für die Kacheln auf der Website
teaser: Dass die generative KI wegen ihrer exorbitant hohen Rechenleistungen sehr viel Energie verbraucht, weiß jeder, der es wissen möchte. Aber wie hoch die ökologischen Kosten des KI-Investment-Booms tatsächlich sind und wie stark sie künftig wachsen werden, darüber reden noch zu wenige. Ein Blogbeitrag.


# Für Social media und Suchergebnisse (also extern)
meta_beschreibung: Dass die generative KI wegen ihrer exorbitant hohen Rechenleistungen sehr viel Energie verbraucht, weiß jeder, der es wissen möchte. Aber wie hoch die ökologischen Kosten des KI-Investment-Booms tatsächlich sind und wie stark sie künftig wachsen werden, darüber reden noch zu wenige.

tags: sitemap
lang: de
---
Keine Geldsumme ist offenbar zu groß, um den verbreiteten Glauben an die generative Künstliche Intelligenz zu untermauern. In den nächsten Jahren wollen die US-amerikanischen Tech-Konzerne rund eine Billion US-Dollar in Rechenzentren, Chips, Infrastrukturen und Stromnetze investieren.

Auch US-Präsident Donald Trump kündigte wenige Tage nach seinem Wiedereinzug ins Weiße Haus das „mit Abstand größte KI-Infrastrukturprojekt der Geschichte“ an. Das Projekt läuft unter dem Namen „Stargate“ und soll in den kommenden vier Jahren bis zu <a href="https://www.tagesschau.de/wirtschaft/digitales/stargate-ki-trump-100.html">500 Milliarden US-Dollar</a> in KI-Infrastruktur wie Rechenzentren pumpen.

Auch Europa will in diesem „AI Race“ nicht zurückfallen. Anfang Februar lädt Emmanuel Macron zum <a href="http://aiconference.ip-paris.fr/">AI Action Summit</a> nach Paris – allerdings mit kritischerem Blick auf ökologische und soziale Auswirkungen. Bereits vergangenes Jahr warnte der ehemalige italienische Ministerpräsident Mario Draghi davor, dass <a href="https://commission.europa.eu/topics/strengthening-european-competitiveness/eu-competitiveness-looking-ahead_en">die EU im globalen Wettbewerb zurückfallen</a> könnte, wenn sie nicht enorm investiere.

<h2 class="h4">Hohe Rechenleistungen bedeuten sehr viel Energie</h2>

Doch es gibt eine andere Seite der Medaille: Dass die generative KI wegen ihrer exorbitant hohen Rechenleistungen sehr viel Energie verbraucht, weiß jeder, der es wissen möchte. Mittlerweile zeigt sich zwar auch, dass generative KI overhyped ist – aber selbst wenn sie ein vergängliches Phänomen ist, liegen die ökologischen Kosten hoch und wachsen stetig an. Der KI-Investment-Boom, der politisch kräftig unterstützt wird, benötigt so hohe Rechenkapazitäten – und damit Energie –, dass er die Klimaneutralität zu verhindern droht.

Weltweit regen sich Proteste gegen den Bau von Hyperscale-Rechenzentren – von Zeewolde in den Niederlanden bis Montevideo in Uruguay. Und das nicht ohne Grund: In Uruguay wird das Trinkwasser knapp, eine Folge der sich zuspitzenden Klimakrise, die jedes Jahr neue Höhepunkte erreicht. 2024 überschritt die globale Temperatur erstmals 1,5 Grad. Bei dem jetzigen weltweiten CO2-Verbrauch wird das Weltklima in den nächsten vier Jahren die Marke von 1,5 Grad wohl endgültig überschreiten. Eine neue energiehungrige Technologie sollte also einen möglichst hohen gesellschaftlichen Nutzen haben, um in Zeiten der Klimakrise vertretbar zu sein.

Die tatsächlichen Ausmaße des Energieverbrauchs generativer KI kommen in den öffentlichen Debatten derzeit nur am Rande vor. Daher ist ein Blick auf die Dimensionen und Ressourcen angebracht, welche die von KI-Gläubigen förmlich angebetete Technologie frisst.

Anbieter generativer KI wie Microsoft räumen ein, dass die Expansion solcher KI und der dazugehörige Strombedarf die früheren Emissionsversprechen der Konzerne torpedieren. Der Software-Konzern versprach beispielsweise vollmundig, bis 2030 CO2-negativ zu werden. Microsoft-Vizechef Brad Smith nannte nun die generative KI als Hauptgrund dafür, dass die Konzernemissionen im Vergleich zum Jahr 2020 um etwa dreißig Prozent angestiegen seien.

Microsoft plant nach <a href="https://blogs.microsoft.com/on-the-issues/2025/01/03/the-golden-opportunity-for-american-ai/">Angaben von Smith</a> aktuell, achtzig Milliarden US-Dollar allein im Jahr 2025 in generative KI zu investieren, um seine Vision einer „American AI“ voranzubringen. Mit dieser Summe will das Unternehmen „KI-fähige Rechenzentren aufbauen, in denen KI-Modelle trainiert sowie KI- und Cloud-basierte Anwendungen“ weltweit bereitgestellt werden. Die Energie für diese Investitionen soll unter anderem aus dem stillgelegten <a href="https://www.tagesschau.de/ausland/amerika/usa-atomkraftwerk-microsoft-100.html">Atomkraftwerk Three Mile Island</a> stammen, das Microsoft 2028 wieder in Betrieb nehmen will.


<h2 class="h4">Wie der hohe Energieverbrauch der generativen KI entsteht</h2>

Lange wurde das Training der großen Sprachmodelle als wesentlicher Faktor des Energieverbrauchs diskutiert. <a href="https://arxiv.org/pdf/1906.02243">Bereits 2020</a> zeigten Emma Strubell und andere Fachleute, dass allein das Training eines Large Language Models (LLM) etwa 284 Kilogramm CO2-Emissionen verursacht. Das LLM verfügte über die inzwischen geradezu winzig anmutende Zahl von 213 Millionen Parametern und eine Trainingsdauer von etwa dreieinhalb Tagen.

Die heutigen LLMs weisen hunderte Milliarden Parameter auf, und der Energieverbrauch von US-Rechenzentren ist im Jahr 2023 auf insgesamt 176 Terawattstunden angestiegen. Er macht damit erstaunliche 4,4 Prozent des landesweiten Gesamtstromverbrauchs aus. Ausschlaggebend ist aber nicht mehr nur das Training. Spätestens seit den <a href="https://www.levernews.com/biden-boosts-ai-despite-energy-dept-warning/">Nachrichten über steigende Strompreise</a> durch KI-Einsatz in den Vereinigten Staaten wird klar, dass für die großen generativen Sprachmodelle der gesamte Lebenszyklus – insbesondere die Nutzung – viel relevanter ist.

Das liegt auch daran, dass die Nachfrage erst am Anfang stehen dürfte, sie zumindest aber stetig steigt. Derzeit sind die überwiegenden Anwendungen der generativen KI textbasiert. Doch die multimodalen Anwendungsfälle nehmen sichtbar zu, beispielsweise auch Text-zu-Video. Solche Anwendungsfälle sind unzweifelhaft wesentlich rechenintensiver. Grob berechnet erfordert die Erstellung eines solchen Videos mit generativer KI etwa die hundertfache Energie im Vergleich zu einem entsprechenden textbasierten Output.

Eine im Juni 2024 <a href="https://dl.acm.org/doi/pdf/10.1145/3630106.3658542">veröffentlichte Studie</a> errechnete, dass eintausend Anwendungen von Textgeneratoren durchschnittlich 0,047 Kilowattstunden benötigen. Bei Bildgeneratoren landet man schon bei 2,907 Kilowattstunden. Damit brauchen eintausend KI-generierte Bilder also fast so viel Energie, als würde man zwanzig Kilometer mit dem Elektroauto fahren oder 200 Tassen Kaffee kochen.

Zwar bleibt das einzelne LLM-Training weiterhin um Größenordnungen energie- und kohlenstoffintensiver als die einzelne Nutzung der LLMs. Allerdings zeigt schon die sichtbare Allgegenwart von generativer KI und die milliardenfache tägliche Verwendung, dass der Energieverbrauch der Nutzung wegen ihrer Popularität enorm zunimmt.

<h2 class="h4">Milliarden-Investitionen in Rechenzentren</h2>

Die Debatte um den ökologischen Fußabdruck von großen Sprachmodellen sollte selbstverständlich nicht auf eine persönliche Verbrauchsdiskussion verkürzt werden. Natürlich kann man sich täglich für oder gegen die Generierung von KI-Bildern entscheiden. Aber es wäre zu kurz gesprungen, auf bloße persönliche Entscheidungen abzustellen. Denn es zeichnet sich ab, dass der breite Einsatz von generativer KI schon bald keine individuelle Entscheidung mehr sein wird. Microsoft beispielsweise plant längst, generative KI in seine Betriebssysteme zu integrieren, so dass eine Nutzung künftig schwerer zu vermeiden oder gar unumgänglich wird.

Die geplanten Investitionen von Microsoft in Höhe von achtzig Milliarden US-Dollar pro Jahr sind nur ein Beispiel. Die Aufrüstung der Rechenzentren und der damit einhergehende Energieverbrauch sind so enorm, dass die Umstellung der Energieproduktion hin zu Erneuerbaren dadurch buchstäblich aufgefressen wird.

Besonders gut lässt sich das in Europa illustrieren. Irland ist schon lange einer der beliebtesten Standorte für Rechenzentren, weil Energiekosten dort vergleichsweise niedrig sind. Einige Rechenzentren sind sogar direkt an das dortige Gasnetz angeschlossen, um eine konstante Stromversorgung zu sichern.

Wo die Rechenzentren mit anderen Branchen um erneuerbare Energien konkurrieren, kaufen sie häufig Zertifikate für Erneuerbare auf, ohne eigene grüne Energie einzuspeisen. Diese Energie fehlt dann anderswo. Selbst konservative Berechnungen zeigen, dass die KI-bedingte Energienachfrage von Rechenzentren so schnell wächst, dass der Ausbau der Erneuerbaren Energien nicht mithalten kann.

Damit droht der Energiehunger der Rechenzentren die europäische Klimaneutralität zu gefährden. Das gilt umso mehr, wenn sich der absehbar massiv steigende Bedarf an Rechenzentren noch weiter auf die Energiewende auswirkt.

<h2 class="h4">Elektroschrottmassen</h2>

Aber nicht nur Energie wird massenhaft für den <a href="https://netzpolitik.org/2022/neue-signal-chefin-kuenstliche-intelligenz-ist-vor-allem-ein-marketinghype/">von Marketing getriebenen KI-Boom</a> verbraucht. Für generative KI spielen Graphikprozessoren (GPUs) eine besondere Rolle, die in riesiger Anzahl benötigt werden. Allein der Konzern Meta will bis Ende 2025 sage und schreibe mehr als 1,3 Millionen GPU-Beschleuniger betreiben, wie <a href="https://www.threads.net/@zuck/post/DFNf8bvpP2I">Marc Zuckerberg jüngst mitteilte</a>
.

Der wichtigste Player bei GPUs ist der Konzern Nvidia, von dem fast die gesamte Branche abhängt. Nvidia veröffentlicht zwar keine Lifecycle-Analysen – aber bekannt ist mittlerweile auch hier: Der Ressourcenverbrauch für die Chips ist hoch und die Lieferkette alles andere als sauber.

Einerseits werden die Rohstoffe für Chips wie Silizium und für den Bau von Rechenzentren – von Lithium bis Kobalt – global unter umweltschädlichen und menschenrechtsverletzenden Zuständen abgebaut. Andererseits wird die Hardware kaum recycelt. Erste Berechnungen gehen davon aus, dass allein der Elektroschrott durch das Aussortieren von Servern und anderen Computern von etwa 2.550 Tonnen im Jahr 2023 durch das Anwachsen der generativen KI auf – je nach Szenario – fast schon unglaubliche <a href="https://www.nature.com/articles/s43588-024-00712-6.epdf">0,4 bis zu 2,5 Millionen Tonnen im Jahr 2030 ansteigen könnte</a>.

Die LLM-bezogene Elektromüllmasse wüchse nach diesen Berechnungen bis zum Jahr 2030 um 129 Prozent bis 167 Prozent an. Allerdings sind die gebauten und geplanten KI-Rechenzentren keineswegs gleich auf der Welt verteilt. Sondern sie befinden sich geographisch am häufigsten in Nordamerika (58 Prozent), gefolgt von Ostasien (25 Prozent) und Europa (14 Prozent). Hier fallen dann auch entsprechend die Elektroschrottmassen an. Verschifft und abgelagert werden sie jedoch vor allen Dingen im Globalen Süden, etwa auf der größten Elektroschrotthalde der Welt <a href="https://www.tagesschau.de/ausland/ghana-elektroschrott-101.html">in Ghana</a>.

GPU-Hersteller wie Nvidia haben bisher nur wenige Anreize, um ihre Produktionsbedingungen offenzulegen und etwa konkrete Angaben zu verwendeten Metallen und Mineralien zu machen. Eine Forderung liegt daher auf der Hand: Künftig sollten die Nachhaltigkeitsberichte der GPU-Hersteller zu mehr Transparenz beitragen. Dann hätten etwa Betreiber von Rechenzentren die Möglichkeit, sich für Hardware zu entscheiden, die nachhaltiger hergestellt wurde.

Zwar gibt es in Europa neue Regeln zur Beschaffung von verantwortungsvoll produzierten Mineralien. Die EU-Richtlinien zur Nachhaltigkeitsberichterstattung (CSRD) und zur Nachhaltigkeitsprüfung (CSDDD) brachten ab dem 1. Januar 2024 neue Rechenschaftspflichten für Unternehmen bei Umwelt-, Nachhaltigkeits- und Sozialfragen. Seither sind alle großen europäischen Unternehmen sowie alle EU-börsennotierten Unternehmen auskunftspflichtig. Allerdings gibt es derzeit noch zu wenig Transparenz, um willigen Betreibern von Rechenzentren nachhaltigere Entscheidungsalternativen nahelegen zu können. Das betrifft sowohl den Bergbaubereich, Metalle und Mineralien als auch die Menschenrechte.

<h2 class="h4">Aber kann KI nicht das Klima retten?</h2>

Künstliche Intelligenz kann im Kampf gegen die Klimakrise sinnvoll eingesetzt werden – aber nicht unbedingt generative KI. Selbst der beste Chatbot kann schließlich kein CO2 aus der Luft ziehen.

So gibt es kluge technische Lösungen, die etwa wichtige Daten zur Klimakrise auswerten. Wenn aber die Ergebnisse eines KI-Systems oder einer anderen Software nicht direkt mit einer Handlung verbunden sind, sondern zunächst nur Informationen liefern, dann ist das vielleicht ein Fortschritt, bringt im Klimakampf aber wenig.

Generative KI ist inhärent ein nicht nachhaltiges System. Sie kann zu den Klima- und Nachhaltigkeitszielen wenig bis nichts beitragen. Schlimmer noch: Sowohl die Schaffung großer Sprachmodelle als auch deren Nutzung sind nicht nur nicht nachhaltig, sondern in hohem Maße umweltschädlich. Generative KI bringt also keine Lösung für die Klimakrise, sondern heizt sie massiv an, insbesondere wenn alle weiter kopflos dem Marketingversprechen folgen, wonach generative KI so gut wie alle Branchen quasi revolutionieren werde.

Gegen den KI-Glauben gibt es bisher nur wenig öffentlichen Gegenwind. Doch weltweit wehrt sich die Zivilgesellschaft: von indigenen Bewegungen im schwedischen Teil Sapmís, die gegen Metas Rechenzentren demonstrieren, bis hin zu Protestierenden in Montevideo, die ihr Trinkwasser gegen Verschmutzungen durch Googles Rechenzentren schützen wollen. Doch die Diskussionen um den Energie- und <a href="https://sdgs.un.org/sites/default/files/2024-05/Gupta%2C%20et%20al._AIs%20excessive%20water%20consumption.pdf">Wasserverbrauch</a>, die <a href="https://sdgs.un.org/sites/default/files/2024-05/Rani;%20Gobel;%20Dhir_Development%20of%20AI.pdf">problematischen Arbeitsbedingungen</a> oder auch die kolonialen Kontiunitäten beginnen erst.

Mit Blick auf Deutschland lassen sich im Vorfeld der Bundestagswahl drei zentrale Forderungen in Bezug auf die ökologischen Kosten der generativen KI erheben: Erstens braucht es strenge Transparenz über den Energie- und Ressourcenverbrauch von Rechenzentren. Zweitens sollte staatliche Förderung nur an spezifische KI-Modelle gehen, die explizit Nachhaltigkeitskriterien erfüllen. Und drittens brauchen wir eine breite gesellschaftliche Debatte darüber, ob und wie wir uns umweltschädliche KI-Systeme in Zeiten der Klimakrise leisten können – und wollen.


*Hinweis: Der Artikel erschien zuerst auf <a href="https://netzpolitik.org/2025/generative-ki-klimaschaedlich-by-design/">netzpolitik.org</a>.*

*Über die Autorinnen: Friederike Hildebrant ist Ökonomin, beschäftigt sich mit Klima- und Stadtpolitik und koordiniert das Bits & Bäume- Bündnis. Constanze Kurz ist promovierte Informatikerin und Autorin. Sie ist ehrenamtliche Sprecherin des Chaos Computer Club.*
